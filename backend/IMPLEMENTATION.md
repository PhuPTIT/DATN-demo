# ğŸ¯ Backend Implementation Summary

## âœ… What Has Been Created

### 1. **Project Structure**
```
backend/
â”œâ”€â”€ main.py                          # FastAPI app with 3 endpoints
â”œâ”€â”€ config.py                        # Configuration & paths
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ README.md                        # Comprehensive documentation
â””â”€â”€ models_src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ architectures.py             # PyTorch models (GRUUrl, ByteTransformer, GCNClassifier)
    â”œâ”€â”€ preprocessing.py             # Input processing (URL, HTML, DOM)
    â””â”€â”€ inference.py                 # Model loading & inference wrappers
```

### 2. **3 Endpoints**

#### âœ… POST `/api/check_url_fast` (RNN - URL Model)
```json
Request:  {"url": "https://example.com"}
Response: {"probability": 0.25, "label": "BENIGN", "confidence": 0.92}
```
- **Processing**: Character encoding â†’ GRU inference â†’ softmax
- **Input**: URL string (max 256 chars)
- **Speed**: âš¡ ~20-50ms
- **Uses**: `rnn_best_ema.pt`, `rnn_url_vocab.json`, `rnn_best_threshold.json`

#### âœ… POST `/api/check_html` (Transformer - HTML Model)
```json
Request:  {"html": "<html><body>...</body></html>"}
Response: {"probability": 0.62, "label": "PHISHING", "confidence": 0.78}
```
- **Processing**: UTF-8 byte encoding â†’ multi-window Transformer â†’ average logits
- **Input**: HTML content (max 2048 tokens, 4 windows with 50% overlap)
- **Speed**: ğŸš€ ~100-500ms (multi-window)
- **Uses**: `transformer_byte_best.pt`, `transformer_best_threshold.json`

#### âœ… POST `/api/check_dom` (GCN - DOM Model)
```json
Request:  {"dom": {"nodes": [...], "edges": [...], "label": 0}}
Response: {"probability": 0.58, "label": "PHISHING", "confidence": 0.72}
```
- **Processing**: DOM graph building â†’ GCN inference â†’ softmax
- **Input**: DOM record with nodes (70 features), edges (sparse adjacency)
- **Speed**: ğŸš€ ~100-1000ms (depends on graph size)
- **Uses**: `gnn_best.pt`, `gnn_tag_vocab.json`, `gnn_best_threshold.json`

### 3. **Model Implementations**

#### ğŸ”¹ `GRUUrl` (URL Model)
```python
class GRUUrl(nn.Module):
    - Embedding layer (vocab_size â†’ 64 dims)
    - GRU layer (64 â†’ 128 hidden, bidirectional)
    - Head (128*2 â†’ 128 â†’ 2 logits)
```

#### ğŸ”¹ `ByteTransformer` (HTML Model)
```python
class ByteTransformer(nn.Module):
    - Byte embedding (259 vocab â†’ 192 dims)
    - Positional encoding
    - 4-layer Transformer encoder (192 dims, 6 heads)
    - Global average pooling
    - Classification head (192 â†’ 2 logits)
```

#### ğŸ”¹ `GCNClassifier` (DOM Model)
```python
class GCNClassifier(nn.Module):
    - 2-layer GCN (70 â†’ 128 â†’ 128)
    - Residual connections
    - Graph-level readout (mean + max pooling)
    - Classification head (256 â†’ 2 logits)
```

### 4. **Preprocessing Utilities**

#### URL Processing
```python
encode_url(url, stoi, max_len=256)
  â†’ char encoding + padding
  â†’ [0, max_len) tensor
```

#### HTML Processing
```python
to_byte_ids_windowed(html, max_len=2048, window=None)
  â†’ UTF-8 byte encoding
  â†’ [CLS] + bytes + [SEP]
  â†’ windowing for long HTML
  â†’ [0, max_len) tensor

make_windows(byte_arr, max_len, stride, max_windows)
  â†’ sliding windows with 50% overlap
  â†’ up to 4 windows
```

#### DOM Processing
```python
build_graph_tensors(record, tag2id, f_tag=64)
  â†’ node feature extraction (tag one-hot + attributes)
  â†’ edge normalization (bidirectional + self-loops)
  â†’ sparse adjacency matrix
  â†’ degree computation
```

### 5. **Inference Engine**

#### `UrlModelWrapper`
```python
- Load RNN checkpoint + vocab + threshold
- infer(url) â†’ (probability, label)
```

#### `HtmlModelWrapper`
```python
- Load Transformer checkpoint + threshold
- infer_single(html) â†’ fast single-window
- infer_multi(html) â†’ robust multi-window
```

#### `DomModelWrapper`
```python
- Load GCN checkpoint + tag vocab + threshold
- infer(dom_record) â†’ (probability, label)
```

#### `EnsemblePredictor`
```python
- Combine 3 models with weights
- predict(url, html, dom) â†’ individual + ensemble scores
```

## ğŸš€ How to Use

### Installation
```bash
cd backend
pip install -r requirements.txt
```

### Run Server
```bash
python main.py
# OR
uvicorn main:app --host 0.0.0.0 --port 8000
```

### Test Endpoints
```bash
# Check URL
curl -X POST http://localhost:8000/api/check_url_fast \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'

# Check HTML
curl -X POST http://localhost:8000/api/check_html \
  -H "Content-Type: application/json" \
  -d '{"html": "<html>...</html>"}'

# Check DOM
curl -X POST http://localhost:8000/api/check_dom \
  -H "Content-Type: application/json" \
  -d '{"dom": {"nodes": [], "edges": []}}'
```

## ğŸ“Š Input/Output Specifications

### Input Formats

#### URL Model
```
Input:  string (raw URL)
Format: UTF-8 text
Length: Up to 256 characters (longer strings are truncated)
Example: "https://paypal-verify.com/login?session=abc123"
```

#### HTML Model
```
Input:  string (raw HTML)
Format: UTF-8 text
Length: Up to 2048 bytes per window (4 windows max)
Encoding: UTF-8 bytes â†’ token IDs 0-258
Example: "<html><body><form action='...'></form></body></html>"
```

#### DOM Model
```
Input:  dict with structure:
{
  "nodes": [
    {"tag": "html", "attrs": {}, "text_len": 0},
    {"tag": "body", "attrs": {"class": "main"}},
    {"tag": "a", "attrs": {"href": "http://..."}, "text_len": 10}
  ],
  "edges": [[0, 1], [1, 2]],
  "label": 0
}
```

### Output Format
```json
{
  "probability": float,     # 0.0-1.0, phishing probability
  "label": string,          # "PHISHING" or "BENIGN"
  "confidence": float       # 0.0-1.0, how far from threshold
}
```

## ğŸ” Key Implementation Details

### Thresholds (from checkpoint JSONs)
- **URL**: 0.5 (balanced)
- **HTML**: 0.34 (optimized for F1)
- **DOM**: 0.54 (FÎ²-optimized with floor)

### Feature Dimensions
- **RNN**: 87 character vocabulary
- **Transformer**: 259 byte tokens (0-255 + special tokens)
- **GCN**: 70 features per node (64 tags + 6 extras)

### Model Sizes (on disk)
- **RNN**: ~1-2 MB
- **Transformer**: ~10-15 MB
- **GCN**: ~100-150 KB
- **Vocabs**: ~20 KB each

## ğŸ¯ Next Steps

### 1. **Connect Frontend**
Update frontend API calls to use:
```
POST http://backend-server:8000/api/check_url_fast
POST http://backend-server:8000/api/check_html
POST http://backend-server:8000/api/check_dom
```

### 2. **Deployment**
Options:
- **Local**: `python main.py` (development)
- **Docker**: Create Dockerfile for containerization
- **Cloud**: Deploy to AWS/GCP/Azure with uvicorn
- **Production**: Use Gunicorn + Nginx

### 3. **Monitoring**
- Add logging to track predictions
- Monitor API latency
- Track model accuracy on real data
- Set up alerting for failures

### 4. **Optimization**
- Batch processing for bulk checks
- Caching for repeated URLs
- Model quantization for faster inference
- GPU support (auto-enabled if available)

## ğŸ“ File Descriptions

| File | Purpose |
|------|---------|
| `main.py` | FastAPI app, endpoints, CORS, error handling |
| `config.py` | Paths, model configs, device setup |
| `models_src/architectures.py` | PyTorch model definitions |
| `models_src/preprocessing.py` | Input encoding/decoding utilities |
| `models_src/inference.py` | Model loading & inference wrappers |
| `requirements.txt` | Python dependencies |
| `README.md` | User documentation |

## âœ¨ Features

âœ… 3 independent models with different input modalities  
âœ… Multi-window inference for robustness (HTML)  
âœ… Ensemble prediction combining all 3 models  
âœ… Configurable thresholds and weights  
âœ… CORS enabled for frontend integration  
âœ… Interactive API docs (Swagger UI)  
âœ… Health check endpoints  
âœ… Comprehensive error handling  
âœ… GPU support (auto-detection)  
âœ… Production-ready with uvicorn  

## ğŸ› Debugging

### Check if models load
```bash
curl http://localhost:8000/
# Should show: models_loaded: {url: true, html: true, dom: true}
```

### Test individual model
```bash
curl -X POST http://localhost:8000/api/check_url_fast \
  -d '{"url": "https://example.com"}'
```

### View API documentation
```
http://localhost:8000/docs
```

---

**Enjoy your phishing detection backend! ğŸ›¡ï¸**
